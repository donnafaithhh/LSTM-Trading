{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c873ec37-8b38-45bd-a5f3-916547e51961",
   "metadata": {},
   "source": [
    "This was created by Donna Faith Go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8582cb46-40a5-43e0-bd65-bd35053ac28d",
   "metadata": {},
   "source": [
    "# LSTM Trading\n",
    "In this notebook, I will learn how to implement an LSTM model using pyTorch on a randomly generated portfolio from the S&P 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e7ed41-5889-4098-ac20-10c715d33ffc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T03:52:13.870268Z",
     "iopub.status.busy": "2025-12-25T03:52:13.869272Z",
     "iopub.status.idle": "2025-12-25T03:52:13.877626Z",
     "shell.execute_reply": "2025-12-25T03:52:13.876290Z",
     "shell.execute_reply.started": "2025-12-25T03:52:13.870268Z"
    }
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31cc858-54d9-4066-9f66-8ab739806616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T03:52:13.879130Z",
     "iopub.status.busy": "2025-12-25T03:52:13.879130Z",
     "iopub.status.idle": "2025-12-25T03:52:18.565541Z",
     "shell.execute_reply": "2025-12-25T03:52:18.564523Z",
     "shell.execute_reply.started": "2025-12-25T03:52:13.879130Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "# data gathering\n",
    "import yfinance as yf\n",
    "\n",
    "# LSTM neural network \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# comparing metrics\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, \n",
    "    mean_absolute_error, \n",
    "    r2_score, \n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "\n",
    "# webscraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# for portfolio generation\n",
    "from scipy.optimize import minimize\n",
    "import portfolio\n",
    "\n",
    "# for lstm train test split\n",
    "from typing import Tuple\n",
    "\n",
    "# standardizing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ensuring pep8\n",
    "%load_ext pycodestyle_magic\n",
    "\n",
    "# ignore future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087b7a5a-0b1a-4dfe-86dc-80f4b74b968a",
   "metadata": {},
   "source": [
    "## LSTM from Geeks for Geeks\n",
    "I first learned how to implement an LSTM neural network from [the Geeks for Geeks website](https://www.geeksforgeeks.org/deep-learning/long-short-term-memory-networks-using-pytorch/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38fe1034-9781-4ea7-92d4-9ab2c93fa7c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T03:52:18.566988Z",
     "iopub.status.busy": "2025-12-25T03:52:18.565541Z",
     "iopub.status.idle": "2025-12-25T03:52:18.572778Z",
     "shell.execute_reply": "2025-12-25T03:52:18.571772Z",
     "shell.execute_reply.started": "2025-12-25T03:52:18.566988Z"
    }
   },
   "outputs": [],
   "source": [
    "# create dataframe for comparison\n",
    "cols = [\n",
    "    'dataset used', 'MAPE', 'MAE', 'MSE', 'R2'\n",
    "]\n",
    "results_df = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bddd2d9-1026-46e9-85b7-190ff7d461ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "### Geeks for Geeks Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79f34145-f98b-4155-81e1-0667c2b57c45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T03:52:18.573778Z",
     "iopub.status.busy": "2025-12-25T03:52:18.572778Z",
     "iopub.status.idle": "2025-12-25T03:52:18.581734Z",
     "shell.execute_reply": "2025-12-25T03:52:18.581734Z",
     "shell.execute_reply.started": "2025-12-25T03:52:18.573778Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "t = np.linspace(0, 100, 1000)\n",
    "data = np.sin(t)\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:(i + seq_length)]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\\\n",
    "\n",
    "seq_length = 10\n",
    "X, y = create_sequences(data, seq_length)\n",
    "\n",
    "trainX = torch.tensor(X[:, :, None], dtype=torch.float32)\n",
    "trainY = torch.tensor(y[:, None], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad46c16-de7d-4e69-b92a-6ab228177be4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T03:52:18.583931Z",
     "iopub.status.busy": "2025-12-25T03:52:18.582740Z",
     "iopub.status.idle": "2025-12-25T03:52:18.589413Z",
     "shell.execute_reply": "2025-12-25T03:52:18.589413Z",
     "shell.execute_reply.started": "2025-12-25T03:52:18.583931Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        if h0 is None or c0 is None:\n",
    "            h0 = torch.zeros(self.layer_dim, x.size(\n",
    "                0), self.hidden_dim).to(x.device)\n",
    "            c0 = torch.zeros(self.layer_dim, x.size(\n",
    "                0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])  # Take last time step\n",
    "        return out, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acf26f0c-2ece-45de-befc-5e9d2938be24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T03:52:18.590930Z",
     "iopub.status.busy": "2025-12-25T03:52:18.590930Z",
     "iopub.status.idle": "2025-12-25T03:52:19.978841Z",
     "shell.execute_reply": "2025-12-25T03:52:19.977835Z",
     "shell.execute_reply.started": "2025-12-25T03:52:18.590930Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LSTMModel(input_dim=1, hidden_dim=100, layer_dim=1, output_dim=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edffdc3c-bf74-4332-acb3-088ae2edb0de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T03:52:19.979839Z",
     "iopub.status.busy": "2025-12-25T03:52:19.978841Z",
     "iopub.status.idle": "2025-12-25T03:52:22.928149Z",
     "shell.execute_reply": "2025-12-25T03:52:22.928149Z",
     "shell.execute_reply.started": "2025-12-25T03:52:19.979839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.2866\n",
      "Epoch [20/100], Loss: 0.0900\n",
      "Epoch [30/100], Loss: 0.0379\n",
      "Epoch [40/100], Loss: 0.0184\n",
      "Epoch [50/100], Loss: 0.0027\n",
      "Epoch [60/100], Loss: 0.0004\n",
      "Epoch [70/100], Loss: 0.0008\n",
      "Epoch [80/100], Loss: 0.0003\n",
      "Epoch [90/100], Loss: 0.0001\n",
      "Epoch [100/100], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "h0, c0 = None, None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs, h0, c0 = model(trainX, h0, c0)\n",
    "\n",
    "    loss = criterion(outputs, trainY)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    h0, c0 = h0.detach(), c0.detach()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36ffc4f1-8fdc-48ce-b638-493b27484da3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T03:52:22.929567Z",
     "iopub.status.busy": "2025-12-25T03:52:22.929567Z",
     "iopub.status.idle": "2025-12-25T03:52:23.105030Z",
     "shell.execute_reply": "2025-12-25T03:52:23.104024Z",
     "shell.execute_reply.started": "2025-12-25T03:52:22.929567Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predicted, _, _ = model(trainX, h0, c0)\n",
    "\n",
    "original = data[seq_length:]\n",
    "time_steps = np.arange(seq_length, len(data))\n",
    "\n",
    "predicted[::30] += 0.2\n",
    "predicted[::70] -= 0.2\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_steps, original, label='Original Data')\n",
    "plt.plot(time_steps, predicted.detach().numpy(),\n",
    "         label='Predicted Data', linestyle='--')\n",
    "plt.title('LSTM Model Predictions vs. Original Data')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.savefig('figures/LSTM Model Predictions vs. Original Data.png')\n",
    "plt.close()\n",
    "\n",
    "# getting metrics\n",
    "mape_val = mean_absolute_percentage_error(original, predicted.detach().numpy())\n",
    "mae_val = mean_absolute_error(original, predicted.detach().numpy())\n",
    "mse_val = mean_squared_error(original, predicted.detach().numpy())\n",
    "r2_val = r2_score(original, predicted.detach().numpy())\n",
    "\n",
    "# saving to pandas dataframe\n",
    "new_row = {\n",
    "    'dataset used': 'sin data', \n",
    "    'MAPE': mape_val, \n",
    "    'MAE': mae_val, \n",
    "    'MSE': mse_val, \n",
    "    'R2': r2_val\n",
    "}\n",
    "results_df.loc[len(results_df)] = new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf95ce9-1616-4b2a-bf19-eed4aba917f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "### Other Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37746b81-e1db-49aa-8685-caea619a83fb",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src='figures/Stochastic vs Stationary data.png' />\n",
    "</div>\n",
    "\n",
    "In this section, we want to try looking at the performance of the LSTM model on stationary data. \n",
    "Stationary data is when there is no unit root present in the dataset.\n",
    "Usually, data is turned stationary to make patterns in the dataset more stable and predictable for forecasting models. \n",
    "Non-stationary data with trends or seasonality usually confuses these models, leading to unreliable forecasts.\n",
    "One of the common ways to turn stochastic data to stationary data is to difference it, apply log transformations, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0591345d-f2e4-4ab5-a422-21b4008c6526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "#### Stationary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8070ab7-4d2d-4da6-b10c-9e3eccdabca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T03:52:23.105030Z",
     "iopub.status.busy": "2025-12-25T03:52:23.105030Z",
     "iopub.status.idle": "2025-12-25T03:52:23.299132Z",
     "shell.execute_reply": "2025-12-25T03:52:23.298067Z",
     "shell.execute_reply.started": "2025-12-25T03:52:23.105030Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate 1000 data points\n",
    "np.random.seed(42)\n",
    "num_steps = 1000\n",
    "steps = np.random.choice([-1, 1], size=num_steps)\n",
    "random_walk = np.cumsum(steps)\n",
    "start_value = 50\n",
    "random_walk_with_start = start_value + np.concatenate([[0], random_walk[:-1]])\n",
    "\n",
    "# make it stationary\n",
    "stationary_data = np.diff(random_walk_with_start)\n",
    "\n",
    "# plot the data\n",
    "fig , ax = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "ax[0].plot(random_walk_with_start, label='Stochastic Data')\n",
    "ax[0].set_ylabel('Position')\n",
    "ax[0].set_title('Stochastic Data')\n",
    "\n",
    "ax[1].plot(stationary_data, label='Stationary Data')\n",
    "ax[1].set_ylabel('Difference')\n",
    "ax[1]. set_title('Stationary Data')\n",
    "fig.supylabel('Position')\n",
    "fig.supxlabel('Step Number')\n",
    "fig.suptitle('Stochastic vs Stationary data')\n",
    "plt.savefig('figures/Stochastic vs Stationary data.png')\n",
    "plt.close()\n",
    "# generate x and y\n",
    "seq_length = 20\n",
    "X, y = create_sequences(stationary_data, seq_length)\n",
    "trainX = torch.tensor(X[:, :, None], dtype=torch.float32)\n",
    "trainY = torch.tensor(y[:, None], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08323e15-00c1-4d30-ba8e-3459ea4ce2b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T03:52:23.300131Z",
     "iopub.status.busy": "2025-12-25T03:52:23.300131Z",
     "iopub.status.idle": "2025-12-25T03:53:20.541478Z",
     "shell.execute_reply": "2025-12-25T03:53:20.540314Z",
     "shell.execute_reply.started": "2025-12-25T03:52:23.300131Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.9932\n",
      "Epoch [200/1000], Loss: 0.9245\n",
      "Epoch [300/1000], Loss: 0.2104\n",
      "Epoch [400/1000], Loss: 0.0034\n",
      "Epoch [500/1000], Loss: 0.0000\n",
      "Epoch [600/1000], Loss: 0.0000\n",
      "Epoch [700/1000], Loss: 0.0000\n",
      "Epoch [800/1000], Loss: 0.0001\n",
      "Epoch [900/1000], Loss: 0.0002\n",
      "Epoch [1000/1000], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "h0, c0 = None, None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs, h0, c0 = model(trainX, h0, c0)\n",
    "\n",
    "    loss = criterion(outputs, trainY)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    h0, c0 = h0.detach(), c0.detach()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89cf5973-7c11-40ef-a3c2-511f08e58256",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T03:53:20.542538Z",
     "iopub.status.busy": "2025-12-25T03:53:20.541478Z",
     "iopub.status.idle": "2025-12-25T03:53:20.856610Z",
     "shell.execute_reply": "2025-12-25T03:53:20.855463Z",
     "shell.execute_reply.started": "2025-12-25T03:53:20.542538Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predicted, _, _ = model(trainX, h0, c0)\n",
    "\n",
    "original = stationary_data[seq_length:]\n",
    "time_steps = np.arange(seq_length, len(stationary_data))\n",
    "\n",
    "predicted[::30] += 0.2\n",
    "predicted[::70] -= 0.2\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_steps, original, label='Original Data')\n",
    "plt.plot(time_steps, predicted.detach().numpy(),\n",
    "         label='Predicted Data', linestyle='--')\n",
    "plt.title('LSTM Model Predictions vs. Original Stationary Data')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.savefig('figures/LSTM Model Predictions vs. Original Stationary Data.png')\n",
    "plt.close()\n",
    "\n",
    "# getting metrics\n",
    "mape_val = mean_absolute_percentage_error(original, predicted.detach().numpy())\n",
    "mae_val = mean_absolute_error(original, predicted.detach().numpy())\n",
    "mse_val = mean_squared_error(original, predicted.detach().numpy())\n",
    "r2_val = r2_score(original, predicted.detach().numpy())\n",
    "\n",
    "# saving to pandas dataframe\n",
    "new_row = {\n",
    "    'dataset used': 'stationary data', \n",
    "    'MAPE': mape_val, \n",
    "    'MAE': mae_val, \n",
    "    'MSE': mse_val, \n",
    "    'R2': r2_val\n",
    "}\n",
    "results_df.loc[len(results_df)] = new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8209dff-d274-4b17-84d3-2932b3d74ff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "#### Stochastic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6d5a2c6-cf31-4eef-819b-856c5e465405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T03:53:20.857620Z",
     "iopub.status.busy": "2025-12-25T03:53:20.856610Z",
     "iopub.status.idle": "2025-12-25T03:53:20.863269Z",
     "shell.execute_reply": "2025-12-25T03:53:20.862062Z",
     "shell.execute_reply.started": "2025-12-25T03:53:20.857620Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate x and y\n",
    "seq_length = 20\n",
    "X, y = create_sequences(random_walk_with_start, seq_length)\n",
    "trainX = torch.tensor(X[:, :, None], dtype=torch.float32)\n",
    "trainY = torch.tensor(y[:, None], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb9a2970-e2e7-471c-b0d9-7eef7e5a5cec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T03:53:20.864283Z",
     "iopub.status.busy": "2025-12-25T03:53:20.863777Z",
     "iopub.status.idle": "2025-12-25T03:54:14.794192Z",
     "shell.execute_reply": "2025-12-25T03:54:14.793187Z",
     "shell.execute_reply.started": "2025-12-25T03:53:20.864283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 77.3714\n",
      "Epoch [200/1000], Loss: 24.6150\n",
      "Epoch [300/1000], Loss: 13.7973\n",
      "Epoch [400/1000], Loss: 6.0461\n",
      "Epoch [500/1000], Loss: 3.5963\n",
      "Epoch [600/1000], Loss: 2.2803\n",
      "Epoch [700/1000], Loss: 1.7464\n",
      "Epoch [800/1000], Loss: 1.5498\n",
      "Epoch [900/1000], Loss: 1.4895\n",
      "Epoch [1000/1000], Loss: 1.2694\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "h0, c0 = None, None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs, h0, c0 = model(trainX, h0, c0)\n",
    "\n",
    "    loss = criterion(outputs, trainY)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    h0, c0 = h0.detach(), c0.detach()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e48ab47-c47b-4ddb-9583-2f2fd9e8d6c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T03:54:14.795192Z",
     "iopub.status.busy": "2025-12-25T03:54:14.794192Z",
     "iopub.status.idle": "2025-12-25T03:54:14.948706Z",
     "shell.execute_reply": "2025-12-25T03:54:14.948706Z",
     "shell.execute_reply.started": "2025-12-25T03:54:14.794192Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predicted, _, _ = model(trainX, h0, c0)\n",
    "\n",
    "original = random_walk_with_start[seq_length:]\n",
    "time_steps = np.arange(seq_length, len(random_walk_with_start))\n",
    "\n",
    "predicted[::30] += 0.2\n",
    "predicted[::70] -= 0.2\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_steps, original, label='Original Data')\n",
    "plt.plot(time_steps, predicted.detach().numpy(),\n",
    "         label='Predicted Data', linestyle='--')\n",
    "plt.title('LSTM Model Predictions vs. Original Stochastic Data')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.savefig('figures/LSTM Model Predictions vs. Original Stochastic Data.png')\n",
    "plt.close()\n",
    "\n",
    "# getting metrics\n",
    "mape_val = mean_absolute_percentage_error(original, predicted.detach().numpy())\n",
    "mae_val = mean_absolute_error(original, predicted.detach().numpy())\n",
    "mse_val = mean_squared_error(original, predicted.detach().numpy())\n",
    "r2_val = r2_score(original, predicted.detach().numpy())\n",
    "\n",
    "# saving to pandas dataframe\n",
    "new_row = {\n",
    "    'dataset used': 'stochastic data', \n",
    "    'MAPE': mape_val, \n",
    "    'MAE': mae_val, \n",
    "    'MSE': mse_val, \n",
    "    'R2': r2_val\n",
    "}\n",
    "results_df.loc[len(results_df)] = new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3da5317-4df4-4791-ba28-87ab301950c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "### Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b01bbb56-bc68-4350-afa8-018286ce8e9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T03:54:14.950164Z",
     "iopub.status.busy": "2025-12-25T03:54:14.950164Z",
     "iopub.status.idle": "2025-12-25T03:54:14.963480Z",
     "shell.execute_reply": "2025-12-25T03:54:14.962474Z",
     "shell.execute_reply.started": "2025-12-25T03:54:14.950164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset used</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sin data</td>\n",
       "      <td>0.130210</td>\n",
       "      <td>0.013631</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.996812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stationary data</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.998481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stochastic data</td>\n",
       "      <td>0.016232</td>\n",
       "      <td>1.003409</td>\n",
       "      <td>1.270952</td>\n",
       "      <td>0.990606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset used      MAPE       MAE       MSE        R2\n",
       "0         sin data  0.130210  0.013631  0.001608  0.996812\n",
       "1  stationary data  0.011643  0.011643  0.001518  0.998481\n",
       "2  stochastic data  0.016232  1.003409  1.270952  0.990606"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b9adc8-40ef-4ccf-93cb-639ae81c4324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T00:22:44.225785Z",
     "iopub.status.busy": "2025-12-20T00:22:44.225785Z",
     "iopub.status.idle": "2025-12-20T00:22:44.237862Z",
     "shell.execute_reply": "2025-12-20T00:22:44.236087Z",
     "shell.execute_reply.started": "2025-12-20T00:22:44.225785Z"
    }
   },
   "source": [
    "Based on the table above, it is clear that LSTM works well on either simple datasets, stochastic data, and stationary data. \n",
    "It must be noted that, although it performs better on stationary data, it is not necessarily the better choice because its performance improvement is very minimal.\n",
    "Hence, adding this preprocessing step would not be good or important for the dataset. \n",
    "\n",
    "I want to add that I also tried doing the LSTM with different epochs, and I saw that with more epochs, the LSTM NN works better (I mean obviously! ðŸ™„).\n",
    "However, simpler datasets especially those with seasonality like the sin/cosine wave that was shown in the Geeks for Geeks example can benefit from an LSTM that has less epochs because it is less comuptationally expensive and delivers results that are already satisfactory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c873ec37-8b38-45bd-a5f3-916547e51961",
   "metadata": {},
   "source": [
    "This was created by Donna Faith Go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8582cb46-40a5-43e0-bd65-bd35053ac28d",
   "metadata": {},
   "source": [
    "# LSTM Trading\n",
    "In this notebook, I will learn how to implement an LSTM model using pyTorch on a randomly generated portfolio from the S&P 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31cc858-54d9-4066-9f66-8ab739806616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T08:15:40.548709Z",
     "iopub.status.busy": "2025-12-22T08:15:40.547631Z",
     "iopub.status.idle": "2025-12-22T08:15:43.797336Z",
     "shell.execute_reply": "2025-12-22T08:15:43.797336Z",
     "shell.execute_reply.started": "2025-12-22T08:15:40.548709Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# data gathering\n",
    "import yfinance as yf\n",
    "\n",
    "# LSTM neural network \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# comparing metrics\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, \n",
    "    mean_absolute_error, \n",
    "    r2_score, \n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "\n",
    "# webscraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# for portfolio generation\n",
    "from scipy.optimize import minimize\n",
    "import portfolio\n",
    "\n",
    "# ensuring pep8\n",
    "%load_ext pycodestyle_magic\n",
    "\n",
    "# ignore future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e7ed41-5889-4098-ac20-10c715d33ffc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T08:15:43.798391Z",
     "iopub.status.busy": "2025-12-22T08:15:43.798391Z",
     "iopub.status.idle": "2025-12-22T08:15:43.802390Z",
     "shell.execute_reply": "2025-12-22T08:15:43.801843Z",
     "shell.execute_reply.started": "2025-12-22T08:15:43.798391Z"
    }
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087b7a5a-0b1a-4dfe-86dc-80f4b74b968a",
   "metadata": {},
   "source": [
    "## LSTM from Geeks for Geeks\n",
    "I first learned how to implement an LSTM neural network from [the Geeks for Geeks website](https://www.geeksforgeeks.org/deep-learning/long-short-term-memory-networks-using-pytorch/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38fe1034-9781-4ea7-92d4-9ab2c93fa7c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T08:15:43.803338Z",
     "iopub.status.busy": "2025-12-22T08:15:43.802390Z",
     "iopub.status.idle": "2025-12-22T08:15:43.811570Z",
     "shell.execute_reply": "2025-12-22T08:15:43.811570Z",
     "shell.execute_reply.started": "2025-12-22T08:15:43.803338Z"
    }
   },
   "outputs": [],
   "source": [
    "# create dataframe for comparison\n",
    "cols = [\n",
    "    'dataset used', 'MAPE', 'MAE', 'MSE', 'R2'\n",
    "]\n",
    "results_df = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bddd2d9-1026-46e9-85b7-190ff7d461ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "### Original Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79f34145-f98b-4155-81e1-0667c2b57c45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T08:15:43.811570Z",
     "iopub.status.busy": "2025-12-22T08:15:43.811570Z",
     "iopub.status.idle": "2025-12-22T08:15:43.821103Z",
     "shell.execute_reply": "2025-12-22T08:15:43.821103Z",
     "shell.execute_reply.started": "2025-12-22T08:15:43.811570Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "t = np.linspace(0, 100, 1000)\n",
    "data = np.sin(t)\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:(i + seq_length)]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\\\n",
    "\n",
    "seq_length = 10\n",
    "X, y = create_sequences(data, seq_length)\n",
    "\n",
    "trainX = torch.tensor(X[:, :, None], dtype=torch.float32)\n",
    "trainY = torch.tensor(y[:, None], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad46c16-de7d-4e69-b92a-6ab228177be4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T08:15:43.822730Z",
     "iopub.status.busy": "2025-12-22T08:15:43.822338Z",
     "iopub.status.idle": "2025-12-22T08:15:43.826954Z",
     "shell.execute_reply": "2025-12-22T08:15:43.826954Z",
     "shell.execute_reply.started": "2025-12-22T08:15:43.822730Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        if h0 is None or c0 is None:\n",
    "            h0 = torch.zeros(self.layer_dim, x.size(\n",
    "                0), self.hidden_dim).to(x.device)\n",
    "            c0 = torch.zeros(self.layer_dim, x.size(\n",
    "                0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])  # Take last time step\n",
    "        return out, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf26f0c-2ece-45de-befc-5e9d2938be24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T08:15:43.826954Z",
     "iopub.status.busy": "2025-12-22T08:15:43.826954Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LSTMModel(input_dim=1, hidden_dim=100, layer_dim=1, output_dim=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edffdc3c-bf74-4332-acb3-088ae2edb0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "h0, c0 = None, None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs, h0, c0 = model(trainX, h0, c0)\n",
    "\n",
    "    loss = criterion(outputs, trainY)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    h0, c0 = h0.detach(), c0.detach()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ffc4f1-8fdc-48ce-b638-493b27484da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predicted, _, _ = model(trainX, h0, c0)\n",
    "\n",
    "original = data[seq_length:]\n",
    "time_steps = np.arange(seq_length, len(data))\n",
    "\n",
    "predicted[::30] += 0.2\n",
    "predicted[::70] -= 0.2\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_steps, original, label='Original Data')\n",
    "plt.plot(time_steps, predicted.detach().numpy(),\n",
    "         label='Predicted Data', linestyle='--')\n",
    "plt.title('LSTM Model Predictions vs. Original Data')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.savefig('figures/LSTM Model Predictions vs. Original Data.png')\n",
    "plt.close()\n",
    "\n",
    "# getting metrics\n",
    "mape_val = mean_absolute_percentage_error(original, predicted.detach().numpy())\n",
    "mae_val = mean_absolute_error(original, predicted.detach().numpy())\n",
    "mse_val = mean_squared_error(original, predicted.detach().numpy())\n",
    "r2_val = r2_score(original, predicted.detach().numpy())\n",
    "\n",
    "# saving to pandas dataframe\n",
    "new_row = {\n",
    "    'dataset used': 'sin data', \n",
    "    'MAPE': mape_val, \n",
    "    'MAE': mae_val, \n",
    "    'MSE': mse_val, \n",
    "    'R2': r2_val\n",
    "}\n",
    "results_df.loc[len(results_df)] = new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf95ce9-1616-4b2a-bf19-eed4aba917f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "### Other Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37746b81-e1db-49aa-8685-caea619a83fb",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src='figures/Stochastic vs Stationary data.png' />\n",
    "</div>\n",
    "\n",
    "In this section, we want to try looking at the performance of the LSTM model on stationary data. \n",
    "Stationary data is when there is no unit root present in the dataset.\n",
    "Usually, data is turned stationary to make patterns in the dataset more stable and predictable for forecasting models. \n",
    "Non-stationary data with trends or seasonality usually confuses these models, leading to unreliable forecasts.\n",
    "One of the common ways to turn stochastic data to stationary data is to difference it, apply log transformations, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0591345d-f2e4-4ab5-a422-21b4008c6526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "#### Stationary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8070ab7-4d2d-4da6-b10c-9e3eccdabca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 1000 data points\n",
    "np.random.seed(42)\n",
    "num_steps = 1000\n",
    "steps = np.random.choice([-1, 1], size=num_steps)\n",
    "random_walk = np.cumsum(steps)\n",
    "start_value = 50\n",
    "random_walk_with_start = start_value + np.concatenate([[0], random_walk[:-1]])\n",
    "\n",
    "# make it stationary\n",
    "stationary_data = np.diff(random_walk_with_start)\n",
    "\n",
    "# plot the data\n",
    "fig , ax = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "ax[0].plot(random_walk_with_start, label='Stochastic Data')\n",
    "ax[0].set_ylabel('Position')\n",
    "ax[0].set_title('Stochastic Data')\n",
    "\n",
    "ax[1].plot(stationary_data, label='Stationary Data')\n",
    "ax[1].set_ylabel('Difference')\n",
    "ax[1]. set_title('Stationary Data')\n",
    "fig.supylabel('Position')\n",
    "fig.supxlabel('Step Number')\n",
    "fig.suptitle('Stochastic vs Stationary data')\n",
    "plt.savefig('figures/Stochastic vs Stationary data.png')\n",
    "plt.close()\n",
    "# generate x and y\n",
    "seq_length = 20\n",
    "X, y = create_sequences(stationary_data, seq_length)\n",
    "trainX = torch.tensor(X[:, :, None], dtype=torch.float32)\n",
    "trainY = torch.tensor(y[:, None], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08323e15-00c1-4d30-ba8e-3459ea4ce2b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "h0, c0 = None, None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs, h0, c0 = model(trainX, h0, c0)\n",
    "\n",
    "    loss = criterion(outputs, trainY)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    h0, c0 = h0.detach(), c0.detach()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf5973-7c11-40ef-a3c2-511f08e58256",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predicted, _, _ = model(trainX, h0, c0)\n",
    "\n",
    "original = stationary_data[seq_length:]\n",
    "time_steps = np.arange(seq_length, len(stationary_data))\n",
    "\n",
    "predicted[::30] += 0.2\n",
    "predicted[::70] -= 0.2\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_steps, original, label='Original Data')\n",
    "plt.plot(time_steps, predicted.detach().numpy(),\n",
    "         label='Predicted Data', linestyle='--')\n",
    "plt.title('LSTM Model Predictions vs. Original Stationary Data')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.savefig('figures/LSTM Model Predictions vs. Original Stationary Data.png')\n",
    "plt.close()\n",
    "\n",
    "# getting metrics\n",
    "mape_val = mean_absolute_percentage_error(original, predicted.detach().numpy())\n",
    "mae_val = mean_absolute_error(original, predicted.detach().numpy())\n",
    "mse_val = mean_squared_error(original, predicted.detach().numpy())\n",
    "r2_val = r2_score(original, predicted.detach().numpy())\n",
    "\n",
    "# saving to pandas dataframe\n",
    "new_row = {\n",
    "    'dataset used': 'stationary data', \n",
    "    'MAPE': mape_val, \n",
    "    'MAE': mae_val, \n",
    "    'MSE': mse_val, \n",
    "    'R2': r2_val\n",
    "}\n",
    "results_df.loc[len(results_df)] = new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8209dff-d274-4b17-84d3-2932b3d74ff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "#### Stochastic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d5a2c6-cf31-4eef-819b-856c5e465405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate x and y\n",
    "seq_length = 20\n",
    "X, y = create_sequences(random_walk_with_start, seq_length)\n",
    "trainX = torch.tensor(X[:, :, None], dtype=torch.float32)\n",
    "trainY = torch.tensor(y[:, None], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a2970-e2e7-471c-b0d9-7eef7e5a5cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "h0, c0 = None, None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs, h0, c0 = model(trainX, h0, c0)\n",
    "\n",
    "    loss = criterion(outputs, trainY)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    h0, c0 = h0.detach(), c0.detach()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e48ab47-c47b-4ddb-9583-2f2fd9e8d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predicted, _, _ = model(trainX, h0, c0)\n",
    "\n",
    "original = random_walk_with_start[seq_length:]\n",
    "time_steps = np.arange(seq_length, len(random_walk_with_start))\n",
    "\n",
    "predicted[::30] += 0.2\n",
    "predicted[::70] -= 0.2\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_steps, original, label='Original Data')\n",
    "plt.plot(time_steps, predicted.detach().numpy(),\n",
    "         label='Predicted Data', linestyle='--')\n",
    "plt.title('LSTM Model Predictions vs. Original Stochastic Data')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.savefig('figures/LSTM Model Predictions vs. Original Stochastic Data.png')\n",
    "plt.close()\n",
    "# getting metrics\n",
    "mape_val = mean_absolute_percentage_error(original, predicted.detach().numpy())\n",
    "mae_val = mean_absolute_error(original, predicted.detach().numpy())\n",
    "mse_val = mean_squared_error(original, predicted.detach().numpy())\n",
    "r2_val = r2_score(original, predicted.detach().numpy())\n",
    "\n",
    "# saving to pandas dataframe\n",
    "new_row = {\n",
    "    'dataset used': 'stochastic data', \n",
    "    'MAPE': mape_val, \n",
    "    'MAE': mae_val, \n",
    "    'MSE': mse_val, \n",
    "    'R2': r2_val\n",
    "}\n",
    "results_df.loc[len(results_df)] = new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3da5317-4df4-4791-ba28-87ab301950c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "### Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01bbb56-bc68-4350-afa8-018286ce8e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b9adc8-40ef-4ccf-93cb-639ae81c4324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T00:22:44.225785Z",
     "iopub.status.busy": "2025-12-20T00:22:44.225785Z",
     "iopub.status.idle": "2025-12-20T00:22:44.237862Z",
     "shell.execute_reply": "2025-12-20T00:22:44.236087Z",
     "shell.execute_reply.started": "2025-12-20T00:22:44.225785Z"
    }
   },
   "source": [
    "Based on the table above, it is clear that LSTM works well on either simple datasets, stochastic data, and stationary data. \n",
    "It must be noted that, although it performs better on stationary data, it is not necessarily the better choice because its performance improvement is very minimal.\n",
    "Hence, adding this preprocessing step would not be good or important for the dataset. \n",
    "\n",
    "I want to add that I also tried doing the LSTM with different epochs, and I saw that with more epochs, the LSTM NN works better (I mean obviously! ðŸ™„).\n",
    "However, simpler datasets especially those with seasonality like the sin/cosine wave that was shown in the Geeks for Geeks example can benefit from an LSTM that has less epochs because it is less comuptationally expensive and delivers results that are already satisfactory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7416b01-fd66-44a8-aa00-d223d75da223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "## Portfolio Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab2b2f7-f930-42fb-95ee-300fc44dbd75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "### Data for 100 randomly selected stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee2a56e-210e-46bd-9aa4-d55b2c038936",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "For this portion, we are randomly selecting 100 stocks from the S&p 500 to create our portfolio.\n",
    "The size of 100 was chosen because we want a diverse portfolio.\n",
    "Furthermore, we also scraped the GSPC stock price because it is the ticker symbol for the S&P 500.\n",
    "Usually, this is used as a benchmark for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ad1bf7-8724-4a90-8695-ea6cb004605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the stock tickers\n",
    "headers = {\n",
    "    'User-Agent': (\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
    "        '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    )\n",
    "}\n",
    "\n",
    "response = requests.get(\n",
    "    \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\",\n",
    "    headers=headers\n",
    ")\n",
    "response.raise_for_status()\n",
    "tables = pd.read_html(response.text)\n",
    "\n",
    "if len(tables) > 0:\n",
    "    stocks_df = tables[0]\n",
    "\n",
    "# randomly selecting 30 stocks\n",
    "random_stocks = stocks_df['Symbol'].sample(n=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36cf75-e582-48d1-8339-b9bedd35facf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# getting closing prices for the 30 stocks with batching\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "def download_stocks_in_batches(tickers, batch_size=5, delay=1):\n",
    "    \"\"\"\n",
    "    Download stock data in batches to avoid rate limiting\n",
    "    \"\"\"\n",
    "    all_data = {}\n",
    "    \n",
    "    for i in range(0, len(tickers), batch_size):\n",
    "        batch = tickers[i:i + batch_size]\n",
    "        print(f\"Downloading batch {i//batch_size + 1}: {batch}\")\n",
    "        \n",
    "        try:\n",
    "            # Download the batch\n",
    "            batch_data = yf.download(\n",
    "                batch,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                progress=False\n",
    "            )\n",
    "            \n",
    "            # Extract closing prices for this batch\n",
    "            if not batch_data.empty and 'Close' in batch_data.columns:\n",
    "                closes = batch_data['Close']\n",
    "                if isinstance(closes, pd.Series):\n",
    "                    all_data[batch[0]] = closes\n",
    "                else:\n",
    "                    for ticker in closes.columns:\n",
    "                        all_data[ticker] = closes[ticker]\n",
    "                print(f\"Successfully downloaded {len(batch)} stocks\")\n",
    "            else:\n",
    "                print(f\"No data returned for batch: {batch}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading batch {batch}: {e}\")\n",
    "        \n",
    "        # Add delay to avoid rate limiting\n",
    "        if i + batch_size < len(tickers):\n",
    "            print(f\"Waiting {delay} seconds before next batch...\")\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    if all_data:\n",
    "        return pd.DataFrame(all_data)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# # Download in batches of 5 stocks with 1-second delay\n",
    "# closing_df = download_stocks_in_batches(\n",
    "#     random_stocks.tolist(), \n",
    "#     batch_size=5, \n",
    "#     delay=15\n",
    "# )\n",
    "\n",
    "# if not closing_df.empty:\n",
    "#     closing_df.to_pickle('closing prices.pkl')\n",
    "\n",
    "# closing_df.head(5)\n",
    "\n",
    "# # Download in batches of 5 stocks with 1-second delay\n",
    "# closing_df = download_stocks_in_batches(\n",
    "#     ['^GSPC'], \n",
    "#     batch_size=5, \n",
    "#     delay=15\n",
    "# )\n",
    "\n",
    "# if not closing_df.empty:\n",
    "#     closing_df.to_pickle('gspc prices.pkl')\n",
    "\n",
    "# closing_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2856d2e-ca86-4bf6-a6f0-c3b0b669a330",
   "metadata": {},
   "source": [
    "Note: The code above takes around 5 minutes to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f9fd19-fafc-4a8e-a53d-ded1fc0a3fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening pkl file\n",
    "filename = r'closing prices.pkl'\n",
    "with open(filename, 'rb') as f: \n",
    "    closing_df = pickle.load(f)\n",
    "    closing_df.index = pd.to_datetime(closing_df.index)\n",
    "\n",
    "# getting s&p 500 data\n",
    "filename = r'gspc prices.pkl'\n",
    "with open(filename, 'rb') as f: \n",
    "    gspc_df = pickle.load(f)\n",
    "    gspc_df.index = pd.to_datetime(gspc_df.index)\n",
    "gspc_df.rename(columns={'^GSPC': 'GSPC'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf4268a-eac3-48d7-8100-d387c448c2ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "### Assigning weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff72c67-e964-4de1-a33d-02f729ec8d4a",
   "metadata": {},
   "source": [
    "Usually, assigning weights yearly for the firms in your portfolio would make more sense.\n",
    "Patterns in firms change as they have to account for new external factors every year such as shifting market conditions, competition from other firms, and more. \n",
    "By changing the weights annually, we are able to incorporate recent financial performance and adjust for any structural changes in the companies.\n",
    "\n",
    "To make things simple, I will use the Markowitz Portfolio Optimization model to assign weights to the different stocks.\n",
    "Here, the best portfolios were chosen based on their Sharpe ratio.\n",
    "For context, the Sharpe Ratio measures an investment's risk-adjusted return. \n",
    "It indicates how much extra return you get for the extra volatility (risk) you take on compared to a risk-free asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d23638f-8a6c-4096-a0c8-8042c7bc609b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'year', 'expected return', 'volatility', 'sharpe ratio'\n",
    "]\n",
    "results_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "# generate portfolios\n",
    "years = ['2022', '2023', '2024']\n",
    "for year in years:\n",
    "    p = portfolio.generate_portfolio(\n",
    "        closing_df.loc[year],\n",
    "        year\n",
    "    )\n",
    "    weights, results, stocks = p.get_portfolio()\n",
    "    ef_portfolio = pd.Series(weights, index=stocks)\n",
    "    ef_portfolio.to_pickle(\n",
    "        f'portfolios/{year} ef portfolio.pkl'\n",
    "    )\n",
    "    results_df.loc[len(results_df)] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1673fb-3ff0-4173-8789-12ac4c63069b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "## LSTM NN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e9821-33fc-43fc-8ca0-866262dd9e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb18d4ab-5492-407f-94c8-234a3b3baa92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ce4fcc-53c9-47c9-9a96-b937c737de28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "262ed74b-92b9-459a-b366-d49b258a9fe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T23:56:24.280293Z",
     "iopub.status.busy": "2025-12-19T23:56:24.275153Z",
     "iopub.status.idle": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply": "2025-12-19T23:56:24.284036Z",
     "shell.execute_reply.started": "2025-12-19T23:56:24.280293Z"
    }
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c7621-6109-430b-9bb5-87e11aa23b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
